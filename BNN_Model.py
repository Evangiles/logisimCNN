import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import random
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os

# --- Interactive Data Generator import ---
try:
    from interactive_data_generator import BinaryDigitDataGenerator, InteractiveTemplateCreator
    print("âœ… Interactive Data Generator ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError:
    print("âš ï¸ Interactive Data Generator ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    BinaryDigitDataGenerator = None

# --- ê¸°ì¡´ EnhancedBinaryDigitGenerator í´ë˜ìŠ¤ import ---
#from Gemini_code1 import EnhancedBinaryDigitGenerator, create_enhanced_binary_digit_dataset

# --- 1-bit ì–‘ìí™”ë¥¼ ìœ„í•œ STE (Straight Through Estimator) ---
class BinarizeWeightSTE(torch.autograd.Function):
    @staticmethod
    def forward(ctx, weight_real):
        binary_weight = weight_real.sign()
        binary_weight[binary_weight == 0] = 1  # 0ì¸ ê²½ìš° +1ë¡œ ê°•ì œ
        return binary_weight

    @staticmethod
    def backward(ctx, grad_output_binary_weight):
        return grad_output_binary_weight

class BinarizeActivationSTE(torch.autograd.Function):
    @staticmethod
    def forward(ctx, activation_real):
        ctx.save_for_backward(activation_real)
        return activation_real.sign()  # {-1, 1}ë¡œ ì´ì§„í™”

    @staticmethod
    def backward(ctx, grad_output_binary_activation):
        activation_real, = ctx.saved_tensors
        grad_input = grad_output_binary_activation.clone()
        # STEì˜ ì¼ë°˜ì ì¸ í´ë¦¬í•‘: ì…ë ¥ì´ ë„ˆë¬´ í¬ë©´ ê·¸ë˜ë””ì–¸íŠ¸ ì „ë‹¬ ì•ˆí•¨
        grad_input[activation_real.abs() > 1.0] = 0
        return grad_input

class BinarizeActivation(nn.Module):
    def forward(self, x):
        return BinarizeActivationSTE.apply(x)

# --- sReLU (Shifted ReLU) í™œì„±í™” í•¨ìˆ˜ ---
class sReLU(nn.Module):
    """
    Shifted ReLU: max(-1, x)
    ë…¼ë¬¸: "Single-bit-per-weight deep convolutional neural networks without batch-normalization"
    BN-ReLU ì¡°í•©ì„ ëŒ€ì²´í•˜ëŠ” í™œì„±í™” í•¨ìˆ˜
    """
    def forward(self, x):
        return torch.clamp(x, min=-1.0)  # max(-1, x)

# --- Binary Linear Layer (He ì´ˆê¸°í™” ì ìš©) ---
class BinaryLinear(nn.Module):
    def __init__(self, in_features, out_features, use_bias=False):
        super(BinaryLinear, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.use_bias = use_bias
        
        # He ì´ˆê¸°í™” (MSRA ì´ˆê¸°í™”)
        std = np.sqrt(2.0 / in_features)
        self.weight = nn.Parameter(torch.randn(out_features, in_features) * std)
        
        if use_bias:
            self.bias = nn.Parameter(torch.zeros(out_features))
        else:
            self.register_parameter('bias', None)

    def forward(self, x):
        binary_weight = BinarizeWeightSTE.apply(self.weight)
        return F.linear(x, binary_weight, self.bias)

# --- Binary Convolutional Layer (He ì´ˆê¸°í™” ì ìš©) ---
class BinaryConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, use_bias=False, padding_value=-1.0):
        super(BinaryConv2d, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.use_bias = use_bias
        self.padding_value = padding_value
        
        # He ì´ˆê¸°í™” (MSRA ì´ˆê¸°í™”)
        fan_in = in_channels * kernel_size * kernel_size
        std = np.sqrt(2.0 / fan_in)
        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size) * std)
        
        if use_bias:
            self.bias = nn.Parameter(torch.zeros(out_channels))
        else:
            self.register_parameter('bias', None)

    def forward(self, x):
        binary_weight = BinarizeWeightSTE.apply(self.weight)
        
        # íŒ¨ë”©ì´ í•„ìš”í•œ ê²½ìš°, ì§€ì •ëœ ê°’ìœ¼ë¡œ íŒ¨ë”© ì ìš©
        if self.padding > 0:
            # (left, right, top, bottom) ìˆœì„œë¡œ íŒ¨ë”©
            pad = (self.padding, self.padding, self.padding, self.padding)
            x = F.pad(x, pad, mode='constant', value=self.padding_value)
            # íŒ¨ë”©ì„ ì´ë¯¸ ì ìš©í–ˆìœ¼ë¯€ë¡œ conv2dì—ì„œëŠ” padding=0
            return F.conv2d(x, binary_weight, self.bias, self.stride, padding=0)
        else:
            return F.conv2d(x, binary_weight, self.bias, self.stride, self.padding)

# --- ìƒìˆ˜ ìŠ¤ì¼€ì¼ë§ ë ˆì´ì–´ ---
class ConstantScaling(nn.Module):
    """
    ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ ìƒìˆ˜ ìŠ¤ì¼€ì¼ë§ ë ˆì´ì–´
    ë§ˆì§€ë§‰ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì™€ GAP ì‚¬ì´ì— ìœ„ì¹˜
    ëª¨ë“  ì±„ë„ì— ë™ì¼í•œ ìƒìˆ˜ ê°’ì„ ê³±í•¨ (í´ë˜ìŠ¤ ìˆ˜ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •)
    """
    def __init__(self, scale_value=10.0):
        super(ConstantScaling, self).__init__()
        self.scale_value = scale_value
        
    def forward(self, x):
        return x * self.scale_value

# --- ì»¤ìŠ¤í…€ Global Average Pooling ---
class CustomGAP(nn.Module):
    """
    ì‚¬ìš©ì ì •ì˜ Global Average Pooling.
    ê³µê°„ ì°¨ì›(H, W)ì— ëŒ€í•´ í•©ì‚°í•œ í›„, ì§€ì •ëœ ê°’ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    """
    def __init__(self, divisor=16.0):
        super(CustomGAP, self).__init__()
        # ì‚¬ìš©ìê°€ ìš”ì²­í•œ 16ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ìœ„í•œ divisor
        self.divisor = float(divisor)
        
    def forward(self, x):
        # ê³µê°„ ì°¨ì›(H, W)ì— ëŒ€í•´ í•©ì‚°. ê²°ê³¼ shape: (N, C, 1, 1)
        spatial_sum = torch.sum(x, dim=(-2, -1), keepdim=True)
        # ì§€ì •ëœ ê°’(16)ìœ¼ë¡œ ë‚˜ëˆ”
        return spatial_sum / self.divisor

# --- ë…¼ë¬¸ ê¸°ë°˜ BNN ëª¨ë¸ (BN ì—†ìŒ, sReLU ì‚¬ìš©, MaxPool ì œê±°, Sign í™œì„±í™” ì¶”ê°€) ---
class PaperInspiredBNN(nn.Module):
    """
    "Single-bit-per-weight deep convolutional neural networks without batch-normalization" ë…¼ë¬¸ ê¸°ë°˜ ëª¨ë¸
    - BN ë ˆì´ì–´ ì œê±°
    - sReLU í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš©
    - sReLU í›„ Sign í™œì„±í™” ì¶”ê°€
    - ë§ˆì§€ë§‰ ë‹¨ì— ìƒìˆ˜ ìŠ¤ì¼€ì¼ë§
    - He ì´ˆê¸°í™”
    - MaxPooling ì œê±° (ë” ë§ì€ ê³µê°„ ì •ë³´ ë³´ì¡´)
    """
    def __init__(self, c1_channels=16, c2_channels=32, num_classes=10, scale_value=None):
        super(PaperInspiredBNN, self).__init__()
        
        if scale_value is None:
            scale_value = float(num_classes)  # í´ë˜ìŠ¤ ìˆ˜ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
            
        # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ (MaxPool ì œê±°)
        self.conv1 = BinaryConv2d(1, c1_channels, kernel_size=3, padding=0)
        self.srelu1 = sReLU()
        #self.sign1 = BinarizeActivation()  # sReLU í›„ Sign í™œì„±í™” ì¶”ê°€
        
        # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ (MaxPool ì œê±°) - ì£¼ì„ ì²˜ë¦¬
        #self.conv2 = BinaryConv2d(c1_channels, c2_channels, kernel_size=2, padding=0)
        #self.srelu2 = sReLU()
        # self.sign2 = BinarizeActivation()  # sReLU í›„ Sign í™œì„±í™” ì¶”ê°€
        
        # ìƒìˆ˜ ìŠ¤ì¼€ì¼ë§ ë ˆì´ì–´ (ë…¼ë¬¸ì—ì„œ ì œì•ˆ)
        self.constant_scaling = ConstantScaling(scale_value)
        
        # Custom Global Average Pooling (5x5=25 ëŒ€ì‹  16ìœ¼ë¡œ ë‚˜ëˆ”)
        self.global_avg_pool = CustomGAP(divisor=16.0)
        
        # GAP ì´í›„ sReLU í™œì„±í™” í•¨ìˆ˜
        #self.srelu_after_gap = sReLU()
        self.sign_after_gap = BinarizeActivation()
        
        # ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´ - c1_channels ì‚¬ìš© (conv2 ì œê±°ë¡œ ì¸í•´)
        self.fc = BinaryLinear(c1_channels, num_classes)
        
        print(f"ğŸ“‹ PaperInspiredBNN ì´ˆê¸°í™” ì™„ë£Œ:")
        print(f" - ìƒìˆ˜ ìŠ¤ì¼€ì¼ë§ ê°’: {scale_value}")
        print(f" - í™œì„±í™” í•¨ìˆ˜: sReLU (Conv ì´í›„ + GAP ì´í›„)")
        print(f" - ë°°ì¹˜ ì •ê·œí™”: ì‚¬ìš© ì•ˆí•¨")
        print(f" - MaxPooling: ì‚¬ìš© ì•ˆí•¨ (ê³µê°„ ì •ë³´ ë³´ì¡´)")
        print(f" - Global Pooling: CustomGAP (divisor=16.0)")
        print(f" - GAP ì´í›„ í™œì„±í™”: sReLU (max(-1, x))")
        print(f" - ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´: 1ê°œ (conv1)")
        print(f" - íŒ¨ë”© ê°’: -1.0 (ë°ì´í„° ì¼ê´€ì„±ì„ ìœ„í•´)")
        print(f" - ì´ˆê¸°í™”: He/MSRA ì´ˆê¸°í™”")

    def forward(self, x):
        # ì…ë ¥ reshape: (batch_size, 64) -> (batch_size, 1, 8, 8)
        x = x.view(-1, 1, 8, 8)
        
        # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ (8x8 ìœ ì§€)
        x = self.conv1(x)
        #x = self.srelu1(x)
        #x = self.sign1(x)  # Sign í™œì„±í™” ì¶”ê°€
        
        # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ (8x8 ìœ ì§€) - ì£¼ì„ ì²˜ë¦¬
        #x = self.conv2(x)
        #x = self.srelu2(x)
        #x = self.sign2(x)  # Sign í™œì„±í™” ì¶”ê°€
        
        # ìƒìˆ˜ ìŠ¤ì¼€ì¼ë§ (ë…¼ë¬¸ì˜ í•µì‹¬ ê¸°ë²•)
        x = self.constant_scaling(x)
        
        # Custom Global Average Pooling (5x5 -> 1x1)
        x = self.global_avg_pool(x)
        
        # GAP ì´í›„ sReLU í™œì„±í™” (max(-1, x))
        #x = self.srelu_after_gap(x)
        
        x = self.sign_after_gap(x)  # Sign í™œì„±í™” ì¶”ê°€
        x = x.view(x.size(0), -1)  # Flatten
        
        # ìµœì¢… ë¶„ë¥˜
        x = self.fc(x)
        
        return x

# --- Early Stoppingì„ í¬í•¨í•œ ê°œì„ ëœ í›ˆë ¨ í•¨ìˆ˜ ---
def train_paper_inspired_model(model, X_train, y_train, X_test, y_test, 
                              epochs=300, initial_lr=0.001, weight_decay=1e-4):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    X_train_tensor = torch.FloatTensor(X_train).to(device)
    y_train_tensor = torch.LongTensor(y_train).to(device)
    X_test_tensor = torch.FloatTensor(X_test).to(device)
    y_test_tensor = torch.LongTensor(y_test).to(device)

    criterion = nn.CrossEntropyLoss()
    
    # Adam ì˜µí‹°ë§ˆì´ì € ì‚¬ìš© (ë…¼ë¬¸ì—ì„œ ê¶Œì¥)
    optimizer = optim.Adam(model.parameters(), lr=initial_lr, weight_decay=weight_decay)
    
    # ì½”ì‚¬ì¸ í•™ìŠµë¥  ê°ì‡  (ë…¼ë¬¸ì—ì„œ ì‚¬ìš©)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=initial_lr/100)

    train_losses, train_accuracies, test_accuracies = [], [], []
    best_test_acc = 0.0

    model_name = model.__class__.__name__
    print(f"ğŸš€ {model_name} í›ˆë ¨ ì‹œì‘!")
    print(f" í›ˆë ¨ ë°ì´í„°: {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
    print(f" ì—í¬í¬: {epochs}, ì´ˆê¸° í•™ìŠµë¥ : {initial_lr}")
    print(f" í•™ìŠµë¥  ìŠ¤ì¼€ì¤„: ì½”ì‚¬ì¸ ê°ì‡  (eta_min: {initial_lr/100:.6f})")
    print(f" ê°€ì¤‘ì¹˜ ê°ì‡ : {weight_decay}")
    print(f" Early Stopping: ì‚¬ìš© ì•ˆí•¨ (ì „ì²´ ì—í¬í¬ í›ˆë ¨)")

    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()

        outputs = model(X_train_tensor)
        loss = criterion(outputs, y_train_tensor)
        loss.backward()
        
        optimizer.step()

        model.eval()
        with torch.no_grad():
            train_outputs = model(X_train_tensor)
            train_pred = torch.argmax(train_outputs, dim=1)
            train_acc = (train_pred == y_train_tensor).float().mean()

            test_outputs = model(X_test_tensor)
            test_pred = torch.argmax(test_outputs, dim=1)
            test_acc = (test_pred == y_test_tensor).float().mean()

        scheduler.step()

        train_losses.append(loss.item())
        train_accuracies.append(train_acc.item())
        test_accuracies.append(test_acc.item())


        if (epoch + 1) % 25 == 0 or epoch < 10:
            current_lr = scheduler.get_last_lr()[0]
            log_msg = f'Epoch [{epoch+1:3d}/{epochs}] | Loss: {loss.item():.4f} | ' \
                      f'Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | ' 

            print(log_msg)

    return train_losses, train_accuracies, test_accuracies, model

# --- ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜ ---
def plot_paper_results(train_losses, train_accuracies, test_accuracies):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # Loss í”Œë¡¯
    ax1.plot(train_losses, 'b-', linewidth=2, alpha=0.8)
    ax1.set_title('Training Loss (Paper-Inspired BNN)', fontsize=14)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.grid(True, alpha=0.3)
    ax1.set_yscale('log')  # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ë” ëª…í™•í•˜ê²Œ ë³´ê¸°
    
    # Accuracy í”Œë¡¯
    ax2.plot(train_accuracies, 'b-', label='Train Accuracy', linewidth=2, alpha=0.8)
    ax2.plot(test_accuracies, 'r-', label='Test Accuracy', linewidth=2, alpha=0.8)
    ax2.set_title('Accuracy (sReLU + Constant Scaling + GAP + sReLU)', fontsize=14)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim([0, 1])
    
    plt.tight_layout()
    plt.show()

# --- ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ ---
def evaluate_paper_model(model, X_test, y_test):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.eval()
    X_test_tensor = torch.FloatTensor(X_test).to(device)

    with torch.no_grad():
        outputs = model(X_test_tensor)
        predictions = torch.argmax(outputs, dim=1)

    print("ğŸ“Š ë…¼ë¬¸ ê¸°ë°˜ ëª¨ë¸ ìƒì„¸ ë¶„ë¥˜ ì„±ëŠ¥:")
    print(classification_report(y_test, predictions.cpu().numpy(),
                                target_names=[str(i) for i in range(10)]))
    
    return predictions.cpu().numpy()

# --- ë°ì´í„°ì…‹ ë¡œë“œ í•¨ìˆ˜ë“¤ ---
def load_dataset_from_npy():
    """ì €ì¥ëœ .npy íŒŒì¼ì—ì„œ ë°ì´í„°ì…‹ ë¡œë“œ (prefix ìë™ ê°ì§€)"""
    
    # ê°€ëŠ¥í•œ prefixë“¤ì„ ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì‹œë„
    prefixes = ['micro_', 'shift_', '', 'augmented_', 'enhanced_']
    
    for prefix in prefixes:
        try:
            print(f"ğŸ“ .npy íŒŒì¼ì—ì„œ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘... (prefix: '{prefix}')")
            X_train = np.load(f'{prefix}X_train.npy')
            X_test = np.load(f'{prefix}X_test.npy')
            y_train = np.load(f'{prefix}y_train.npy')
            y_test = np.load(f'{prefix}y_test.npy')
            
            print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ! (prefix: '{prefix}')")
            print(f" - X_train: {X_train.shape}")
            print(f" - X_test: {X_test.shape}")
            print(f" - y_train: {y_train.shape}")
            print(f" - y_test: {y_test.shape}")
            
            # í´ë˜ìŠ¤ë³„ ë¶„í¬ í™•ì¸
            unique_train, counts_train = np.unique(y_train, return_counts=True)
            unique_test, counts_test = np.unique(y_test, return_counts=True)
            print(f" - í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤ë³„ ë¶„í¬: {dict(zip(unique_train, counts_train))}")
            print(f" - í…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤ë³„ ë¶„í¬: {dict(zip(unique_test, counts_test))}")
            
            return X_train, X_test, y_train, y_test
            
        except FileNotFoundError:
            continue
    
    # ëª¨ë“  prefixë¥¼ ì‹œë„í–ˆì§€ë§Œ ì‹¤íŒ¨
    print(f"âŒ ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ’¡ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì‹¤í–‰í•´ì„œ ë°ì´í„°ì…‹ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”:")
    print("   1. python shift_augmented_dataset.py --visualize")
    print("   2. python interactive_data_generator.py")
    return None, None, None, None

def load_dataset_from_templates(samples_per_digit=500, test_size=0.2, random_state=42):
    """templates.jsonì—ì„œ í…œí”Œë¦¿ì„ ë¡œë“œí•˜ì—¬ ìƒˆ ë°ì´í„°ì…‹ ìƒì„±"""
    try:
        print("ğŸ“‚ templates.jsonì—ì„œ í…œí”Œë¦¿ ë¡œë“œí•˜ì—¬ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        # í…œí”Œë¦¿ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists('templates.json'):
            print("âŒ templates.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ interactive_data_generator.pyë¥¼ ì‹¤í–‰í•´ì„œ í…œí”Œë¦¿ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”!")
            return None, None, None, None
        
        # InteractiveTemplateCreatorë¡œ í…œí”Œë¦¿ ë¡œë“œ
        creator = InteractiveTemplateCreator()
        creator.load_templates('templates.json')
        
        if not creator.templates:
            print("âŒ í…œí”Œë¦¿ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None, None, None, None
        
        # ë°ì´í„° ìƒì„±ê¸° ìƒì„±
        generator = BinaryDigitDataGenerator(creator.templates, creator.template_params)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        X_train, X_test, y_train, y_test = generator.create_dataset(
            samples_per_digit=samples_per_digit, 
            test_size=test_size, 
            random_state=random_state
        )
        
        print(f"âœ… í…œí”Œë¦¿ì—ì„œ ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ!")
        return X_train, X_test, y_train, y_test
        
    except Exception as e:
        print(f"âŒ í…œí”Œë¦¿ì—ì„œ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
        return None, None, None, None

def create_sample_dataset(samples_per_digit=200):
    """ê°„ë‹¨í•œ ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± (í…œí”Œë¦¿ì´ ì—†ì„ ë•Œ í…ŒìŠ¤íŠ¸ìš©)"""
    print("ğŸ² ê°„ë‹¨í•œ ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    
    np.random.seed(42)
    all_X, all_y = [], []
    
    for digit in range(10):
        for _ in range(samples_per_digit):
            # ê°„ë‹¨í•œ íŒ¨í„´ ìƒì„± (8x8 = 64ì°¨ì›)
            sample = np.random.choice([-1, 1], size=64, p=[0.7, 0.3])
            all_X.append(sample)
            all_y.append(digit)
    
    X = np.array(all_X, dtype=np.float32)
    y = np.array(all_y)
    
    # ë°ì´í„° ì…”í”Œ
    indices = np.random.permutation(len(X))
    X, y = X[indices], y[indices]
    
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"âœ… ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    print(f" - ì´ ìƒ˜í”Œ: {len(X)}")
    print(f" - í›ˆë ¨: {len(X_train)}, í…ŒìŠ¤íŠ¸: {len(X_test)}")
    
    return X_train, X_test, y_train, y_test

# --- BNN ëª¨ë¸ í…ŒìŠ¤í„° í´ë˜ìŠ¤ ---
class BNNModelTester:
    """
    ì €ì¥ëœ BNN ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í´ë˜ìŠ¤
    """
    def __init__(self, model_path="interactive_template_bnn_model.pth"):
        self.model_path = model_path
        self.model = None
        self.model_config = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        self.load_model()
    
    def load_model(self):
        """ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            checkpoint = torch.load(self.model_path, map_location=self.device)
            
            # ëª¨ë¸ ì„¤ì • ì •ë³´ ë¡œë“œ
            self.model_config = checkpoint['model_config']
            
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.model = PaperInspiredBNN(
                c1_channels=self.model_config['c1_channels'],
                c2_channels=self.model_config['c2_channels'],
                num_classes=self.model_config['num_classes'],
                scale_value=self.model_config['scale_value']
            )
            
            # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.to(self.device)
            self.model.eval()
            
            print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            print(f"ğŸ“‹ ëª¨ë¸ ì„¤ì •: {self.model_config}")
            
            if 'final_test_accuracy' in checkpoint:
                print(f"ğŸ“Š í›ˆë ¨ ì‹œ ìµœì¢… ì •í™•ë„: {checkpoint['final_test_accuracy']:.4f}")
                print(f"ğŸ† í›ˆë ¨ ì‹œ ìµœê³  ì •í™•ë„: {checkpoint['best_test_accuracy']:.4f}")
                
        except FileNotFoundError:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
            print("ğŸ’¡ ë¨¼ì € BNN_Model.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ì €ì¥í•˜ì„¸ìš”.")
            return
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return
    
    def preprocess_input(self, input_data):
        """
        ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
        input_data: 8x8 numpy array ë˜ëŠ” 64-length vector
        """
        if isinstance(input_data, list):
            input_data = np.array(input_data)
        
        # 8x8 í˜•íƒœë¡œ reshape
        if input_data.shape == (64,):
            input_data = input_data.reshape(8, 8)
        elif input_data.shape != (8, 8):
            raise ValueError(f"ì…ë ¥ ë°ì´í„° í˜•íƒœê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆìƒ: (8,8) ë˜ëŠ” (64,), ì‹¤ì œ: {input_data.shape}")
        
        # ì´ì§„í™” (0 ë˜ëŠ” 1) â†’ (-1 ë˜ëŠ” 1)ë¡œ ë³€í™˜ (í›ˆë ¨ ë°ì´í„°ì™€ ì¼ì¹˜)
        input_data = np.where(input_data > 0.5, 1.0, -1.0).astype(np.float32)
        
        # PyTorch í…ì„œë¡œ ë³€í™˜ (batch dimension ì¶”ê°€)
        input_tensor = torch.FloatTensor(input_data.flatten()).unsqueeze(0).to(self.device)
        
        return input_tensor, input_data
    
    def predict_single(self, input_data, show_visualization=True):
        """
        ë‹¨ì¼ 8x8 ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡
        """
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            # ì…ë ¥ ì „ì²˜ë¦¬
            input_tensor, processed_input = self.preprocess_input(input_data)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            with torch.no_grad():
                output = self.model(input_tensor)
                probabilities = F.softmax(output, dim=1)
                predicted_class = torch.argmax(output, dim=1).item()
                confidence = probabilities[0, predicted_class].item()
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ”® ì˜ˆì¸¡ ê²°ê³¼:")
            print(f"ğŸ“Š ì˜ˆì¸¡ëœ ìˆ«ì: {predicted_class}")
            print(f"ğŸ“ˆ ì‹ ë¢°ë„: {confidence:.4f}")
            
            # ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥  ì¶œë ¥
            print(f"\nğŸ“‹ ëª¨ë“  í´ë˜ìŠ¤ í™•ë¥ :")
            for i in range(10):
                prob = probabilities[0, i].item()
                bar = "â–ˆ" * int(prob * 20)
                print(f"  {i}: {prob:.4f} {bar}")
            
            # ì‹œê°í™”
            if show_visualization:
                self.visualize_prediction(processed_input, predicted_class, confidence, probabilities[0])
            
            return {
                'predicted_class': predicted_class,
                'confidence': confidence,
                'probabilities': probabilities[0].cpu().numpy()
            }
            
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def visualize_prediction(self, input_image, predicted_class, confidence, probabilities):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # ì…ë ¥ ì´ë¯¸ì§€ ì‹œê°í™”
        ax1.imshow(input_image, cmap='gray', interpolation='nearest')
        ax1.set_title(f'ì…ë ¥ ì´ë¯¸ì§€ (8x8)\nì˜ˆì¸¡: {predicted_class} (ì‹ ë¢°ë„: {confidence:.3f})', fontsize=12)
        ax1.set_xticks(range(8))
        ax1.set_yticks(range(8))
        ax1.grid(True, alpha=0.3)
        
        # í™•ë¥  ë¶„í¬ ì‹œê°í™”
        probabilities_np = probabilities.cpu().numpy()
        bars = ax2.bar(range(10), probabilities_np, alpha=0.7)
        bars[predicted_class].set_color('red')  # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ê°•ì¡°
        ax2.set_title('í´ë˜ìŠ¤ë³„ í™•ë¥  ë¶„í¬', fontsize=12)
        ax2.set_xlabel('ìˆ«ì')
        ax2.set_ylabel('í™•ë¥ ')
        ax2.set_xticks(range(10))
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def predict_batch(self, input_batch, labels=None):
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ë°°ì¹˜ ì˜ˆì¸¡
        input_batch: (N, 64) ë˜ëŠ” (N, 8, 8) í˜•íƒœì˜ numpy array
        labels: ground truth labels (optional)
        """
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            # ì…ë ¥ ì „ì²˜ë¦¬
            if len(input_batch.shape) == 3:  # (N, 8, 8)
                input_batch = input_batch.reshape(input_batch.shape[0], -1)  # (N, 64)
            
            # ì´ì§„í™”: (0 ë˜ëŠ” 1) â†’ (-1 ë˜ëŠ” 1)ë¡œ ë³€í™˜ (í›ˆë ¨ ë°ì´í„°ì™€ ì¼ì¹˜)
            input_batch = np.where(input_batch > 0.5, 1.0, -1.0).astype(np.float32)
            input_tensor = torch.FloatTensor(input_batch).to(self.device)
            
            # ë°°ì¹˜ ì˜ˆì¸¡
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = F.softmax(outputs, dim=1)
                predicted_classes = torch.argmax(outputs, dim=1)
            
            predictions = predicted_classes.cpu().numpy()
            
            print(f"\nğŸ”® ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼ ({len(input_batch)}ê°œ ìƒ˜í”Œ):")
            print(f"ğŸ“Š ì˜ˆì¸¡ê°’: {predictions}")
            
            if labels is not None:
                accuracy = (predictions == labels).mean()
                print(f"ğŸ“ˆ ì •í™•ë„: {accuracy:.4f}")
                print(f"\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
                print(classification_report(labels, predictions, target_names=[str(i) for i in range(10)]))
            
            return {
                'predictions': predictions,
                'probabilities': probabilities.cpu().numpy()
            }
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

def create_custom_test_images():
    """ì‚¬ìš©ì ì •ì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì˜ˆì œ"""
    
    # ìˆ«ì '0' íŒ¨í„´ (-1, 1 ê°’ ì‚¬ìš©)
    zero_pattern = np.array([
        [-1, 1, 1, 1, 1, 1, 1, -1],
        [1, 1, -1, -1, -1, -1, 1, 1],
        [1, -1, -1, -1, -1, -1, -1, 1],
        [1, -1, -1, -1, -1, -1, -1, 1],
        [1, -1, -1, -1, -1, -1, -1, 1],
        [1, -1, -1, -1, -1, -1, -1, 1],
        [1, 1, -1, -1, -1, -1, 1, 1],
        [-1, 1, 1, 1, 1, 1, 1, -1]
    ])
    
    # ìˆ«ì '1' íŒ¨í„´ (-1, 1 ê°’ ì‚¬ìš©)
    one_pattern = np.array([
        [-1, -1, -1, 1, 1, -1, -1, -1],
        [-1, -1, 1, 1, 1, -1, -1, -1],
        [-1, 1, 1, 1, 1, -1, -1, -1],
        [-1, -1, -1, 1, 1, -1, -1, -1],
        [-1, -1, -1, 1, 1, -1, -1, -1],
        [-1, -1, -1, 1, 1, -1, -1, -1],
        [-1, -1, -1, 1, 1, -1, -1, -1],
        [1, 1, 1, 1, 1, 1, 1, 1]
    ])
    
    # ìˆ«ì '2' íŒ¨í„´ (-1, 1 ê°’ ì‚¬ìš©)
    two_pattern = np.array([
        [-1, 1, 1, 1, 1, 1, 1, -1],
        [1, 1, -1, -1, -1, -1, 1, 1],
        [-1, -1, -1, -1, -1, -1, 1, 1],
        [-1, -1, -1, -1, -1, 1, 1, -1],
        [-1, -1, -1, 1, 1, 1, -1, -1],
        [-1, 1, 1, 1, -1, -1, -1, -1],
        [1, 1, -1, -1, -1, -1, -1, -1],
        [1, 1, 1, 1, 1, 1, 1, 1]
    ])
    
    return {
        'zero': zero_pattern,
        'one': one_pattern,
        'two': two_pattern
    }

def draw_8x8_image():
    """
    ë§ˆìš°ìŠ¤ë¡œ 8x8 ì´ë¯¸ì§€ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ GUI.
    ì™¼ìª½ í´ë¦­: í”½ì…€ ON(1), ì˜¤ë¥¸ìª½ í´ë¦­: í”½ì…€ OFF(0)
    ì™„ë£Œ í›„ Enterë¥¼ ëˆ„ë¥´ë©´ numpy array ë°˜í™˜
    """
    
    img = np.zeros((8, 8), dtype=np.int32)
    fig, ax = plt.subplots()
    mat = ax.imshow(img, cmap='gray_r', vmin=0, vmax=1)
    ax.set_title("ë§ˆìš°ìŠ¤ë¡œ 8x8 ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ì„¸ìš”\nì™¼ìª½ í´ë¦­: 1, ì˜¤ë¥¸ìª½ í´ë¦­: 0\nì™„ë£Œ í›„ ì°½ì„ ë‹«ìœ¼ì„¸ìš”")
    plt.xticks(range(8))
    plt.yticks(range(8))
    plt.grid(True, color='lightgray', linewidth=1)

    def onclick(event):
        if event.inaxes != ax:
            return
        x, y = int(round(event.xdata)), int(round(event.ydata))
        if 0 <= x < 8 and 0 <= y < 8:
            if event.button == 1:  # ì™¼ìª½ í´ë¦­: 1
                img[y, x] = 1
            elif event.button == 3:  # ì˜¤ë¥¸ìª½ í´ë¦­: 0
                img[y, x] = 0
            mat.set_data(img)
            fig.canvas.draw()

    cid = fig.canvas.mpl_connect('button_press_event', onclick)
    plt.show(block=True)
    fig.canvas.mpl_disconnect(cid)
    return img

def interactive_test():
    """ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    tester = BNNModelTester()
    
    if tester.model is None:
        return
    
    print("\nğŸ¯ BNN ëª¨ë¸ ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    while True:
        print("\nğŸ“ í…ŒìŠ¤íŠ¸ ì˜µì…˜:")
        print("1. ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ í…ŒìŠ¤íŠ¸")
        print("2. ì‚¬ìš©ì ì •ì˜ 8x8 íŒ¨í„´ ì…ë ¥ (í‚¤ë³´ë“œ)")
        print("3. ë§ˆìš°ìŠ¤ë¡œ 8x8 ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°")
        print("4. ì €ì¥ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ë°°ì¹˜ í…ŒìŠ¤íŠ¸")
        print("5. ì¢…ë£Œ")
        
        choice = input("\nì„ íƒí•˜ì„¸ìš” (1-5): ").strip()
        
        if choice == '1':
            # ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ í…ŒìŠ¤íŠ¸
            test_patterns = create_custom_test_images()
            
            print("\nğŸ” ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ í…ŒìŠ¤íŠ¸:")
            for name, pattern in test_patterns.items():
                print(f"\n--- {name.upper()} íŒ¨í„´ í…ŒìŠ¤íŠ¸ ---")
                tester.predict_single(pattern, show_visualization=True)
                
        elif choice == '2':
            # ì‚¬ìš©ì ì •ì˜ ì…ë ¥
            print("\nâœï¸ 8x8 ì´ì§„ íŒ¨í„´ì„ ì…ë ¥í•˜ì„¸ìš” (0 ë˜ëŠ” 1, ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)")
            print("ğŸ’¡ ì…ë ¥ ì˜ˆì‹œ: 0 1 1 0 0 1 1 0")
            print("8ì¤„ì„ ì…ë ¥í•˜ì„¸ìš”:")
            
            try:
                pattern = []
                for i in range(8):
                    line = input(f"ì¤„ {i+1}: ").strip().split()
                    if len(line) != 8:
                        print("âŒ 8ê°œì˜ ê°’ì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
                        break
                    row = [1 if int(x) == 1 else -1 for x in line]  # 0ì„ -1ë¡œ ë³€í™˜
                    pattern.append(row)
                
                if len(pattern) == 8:
                    pattern = np.array(pattern, dtype=np.float32)
                    tester.predict_single(pattern, show_visualization=True)
                    
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš” (0 ë˜ëŠ” 1).")
            except Exception as e:
                print(f"âŒ ì…ë ¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                
        elif choice == '3':
            print("\nğŸ–±ï¸ ë§ˆìš°ìŠ¤ë¡œ 8x8 ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ì„¸ìš”!")
            img = draw_8x8_image()
            # 0ì„ -1ë¡œ ë³€í™˜
            img = np.where(img == 1, 1, -1).astype(np.float32)
            tester.predict_single(img, show_visualization=True)
            
        elif choice == '4':
            # ì €ì¥ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
            try:
                print("\nğŸ“Š ì €ì¥ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ë°°ì¹˜ í…ŒìŠ¤íŠ¸...")
                X_test = np.load('X_test.npy')
                y_test = np.load('y_test.npy')
                
                # ì²˜ìŒ 10ê°œ ìƒ˜í”Œë§Œ í…ŒìŠ¤íŠ¸
                sample_size = min(10, len(X_test))
                X_sample = X_test[:sample_size]
                y_sample = y_test[:sample_size]
                
                result = tester.predict_batch(X_sample, y_sample)
                
            except FileNotFoundError:
                print("âŒ X_test.npy ë˜ëŠ” y_test.npy íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("ğŸ’¡ ë¨¼ì € generate_dataset_no_noise.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ì„¸ìš”.")
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
                
        elif choice == '5':
            print("ğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("âŒ ì˜¬ë°”ë¥¸ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”.")

if __name__ == "__main__":
    print("ğŸ¯ Interactive Template ê¸°ë°˜ BNN ì‹¤í—˜")
    print("ğŸ“„ Based on: Single-bit-per-weight deep CNNs without batch-normalization")
    print("ğŸ¨ Using: Interactive Template Creator Dataset")
    print("="*80)

    # 1. ë°ì´í„°ì…‹ ë¡œë“œ/ìƒì„±
    print("1ï¸âƒ£ ë°ì´í„°ì…‹ ë¡œë“œ/ìƒì„± ì¤‘...")
    
    # ë°©ë²• 1: ì €ì¥ëœ .npy íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
    X_train, X_test, y_train, y_test = load_dataset_from_npy()
    
    # ë°©ë²• 2: .npy íŒŒì¼ì´ ì—†ìœ¼ë©´ templates.jsonì—ì„œ ìƒì„± ì‹œë„  
    if X_train is None and BinaryDigitDataGenerator is not None:
        print("\nğŸ”„ .npy íŒŒì¼ì´ ì—†ì–´ì„œ templates.jsonì—ì„œ ë°ì´í„°ì…‹ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤...")
        X_train, X_test, y_train, y_test = load_dataset_from_templates(
            samples_per_digit=2500, test_size=0.2, random_state=42
        )
    
    # ë°©ë²• 3: ë‘˜ ë‹¤ ì‹¤íŒ¨í•˜ë©´ ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„±
    if X_train is None:
        print("\nğŸ² í…œí”Œë¦¿ë„ ì—†ì–´ì„œ ìƒ˜í”Œ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        X_train, X_test, y_train, y_test = create_sample_dataset(samples_per_digit=300)
        print("âš ï¸ ì´ëŠ” í…ŒìŠ¤íŠ¸ìš© ëœë¤ ë°ì´í„°ì…ë‹ˆë‹¤. ì‹¤ì œ ì‹¤í—˜ì„ ìœ„í•´ì„œëŠ”:")
        print("   1. interactive_data_generator.pyë¥¼ ì‹¤í–‰í•´ì„œ í…œí”Œë¦¿ ìƒì„±")
        print("   2. 'Generate Data' ë²„íŠ¼ìœ¼ë¡œ ë°ì´í„°ì…‹ ì €ì¥")
    
    if X_train is None:
        print("âŒ ë°ì´í„°ì…‹ ë¡œë“œ/ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)
 
    # 2. ë…¼ë¬¸ ê¸°ë°˜ ëª¨ë¸ ìƒì„±
    print("\n2ï¸âƒ£ ë…¼ë¬¸ ê¸°ë°˜ ëª¨ë¸ ìƒì„± ì¤‘...")
    c1_ch, c2_ch = 128, 16  # íŒŒë¼ë¯¸í„° ìˆ˜ ì¤„ì„
    scale_value = 10.0
    
    paper_model = PaperInspiredBNN(c1_channels=c1_ch, c2_channels=c2_ch, 
                                   num_classes=10, scale_value=scale_value)
    
    total_params = sum(p.numel() for p in paper_model.parameters())
    print(f" ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}")

    # 3. ë…¼ë¬¸ ê¸°ë°˜ ëª¨ë¸ í›ˆë ¨
    print("\n3ï¸âƒ£ ë…¼ë¬¸ ê¸°ë°˜ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    train_losses, train_accuracies, test_accuracies, trained_model = train_paper_inspired_model(
        paper_model, X_train, y_train, X_test, y_test,
        epochs=1000, initial_lr=0.001, weight_decay=1e-4  # ì—í¬í¬ ì¤„ì„
    )

    # 4. ê²°ê³¼ ì‹œê°í™”
    print("\n4ï¸âƒ£ ê²°ê³¼ ì‹œê°í™”...")
    plot_paper_results(train_losses, train_accuracies, test_accuracies)

    # 5. ëª¨ë¸ í‰ê°€
    print("\n5ï¸âƒ£ ëª¨ë¸ í‰ê°€...")
    predictions = evaluate_paper_model(trained_model, X_test, y_test)

    # 6. ëª¨ë¸ ì €ì¥
    print("\n6ï¸âƒ£ ëª¨ë¸ ì €ì¥...")
    model_save_path = "interactive_template_bnn_model.pth"
    torch.save({
        'model_state_dict': trained_model.state_dict(),
        'model_config': {
            'c1_channels': c1_ch,
            'c2_channels': c2_ch,
            'num_classes': 10,
            'scale_value': scale_value
        },
        'training_history': {
            'train_losses': train_losses,
            'train_accuracies': train_accuracies,
            'test_accuracies': test_accuracies
        },
        'final_test_accuracy': test_accuracies[-1],
        'best_test_accuracy': max(test_accuracies)
    }, model_save_path)
    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")

    # 7. ì‹¤í—˜ ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“‹ Interactive Template ê¸°ë°˜ BNN ì‹¤í—˜ ìš”ì•½")
    print("="*80)
    print(f"ğŸ¨ ë°ì´í„°: Interactive Template Creatorë¡œ ìƒì„±")
    print(f"ğŸ“Š ë°ì´í„°ì…‹: {len(X_train)} (í›ˆë ¨) + {len(X_test)} (í…ŒìŠ¤íŠ¸)")
    print(f"ğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°: Conv({c1_ch})->sReLU->Scale({scale_value})->GAP->sReLU->FC(10)")
    print(f"âš™ï¸ ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}")
    print(f"ğŸ“ˆ ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracies[-1]:.4f}")
    print(f"ğŸ† ìµœê³  í…ŒìŠ¤íŠ¸ ì •í™•ë„: {max(test_accuracies):.4f}")
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {model_save_path}")

    print("\nğŸ‰ Interactive Template ê¸°ë°˜ BNN ì‹¤í—˜ ì™„ë£Œ!")
    
    # 8. ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ì˜µì…˜
    print("\n" + "="*80)
    print("ğŸ¯ í›ˆë ¨ëœ ëª¨ë¸ì„ ë°”ë¡œ í…ŒìŠ¤íŠ¸í•´ë³¼ê¹Œìš”?")
    print("="*80)
    
    while True:
        choice = input("\ní…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if choice in ['y', 'yes', 'ì˜ˆ', 'ã…‡']:
            print("\nğŸš€ ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ì‹œì‘!")
            interactive_test()
            break
        elif choice in ['n', 'no', 'ì•„ë‹ˆì˜¤', 'ã„´']:
            print("ğŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            break
        else:
            print("âŒ ì˜¬ë°”ë¥¸ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš” (y/n).")
    
    print("\nğŸ¯ BNN ëª¨ë¸ ì‹¤í—˜ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ğŸ’¡ ë‚˜ì¤‘ì— ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰í•˜ì„¸ìš”:")
    print("   from BNN_Model import BNNModelTester, interactive_test")
    print("   interactive_test()")

    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"í˜„ì¬ GPU: {torch.cuda.get_device_name()}")
        print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB") 